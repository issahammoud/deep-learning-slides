{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport glob\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom tqdm import tqdm\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nsns.set()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Exploration","metadata":{}},{"cell_type":"code","source":"train_male = len(os.listdir(\"/kaggle/input/gender-classification-dataset/Training/male\"))\ntrain_female = len(os.listdir(\"/kaggle/input/gender-classification-dataset/Training/female\"))\nvalid_male = len(os.listdir(\"/kaggle/input/gender-classification-dataset/Validation/male\"))\nvalid_female = len(os.listdir(\"/kaggle/input/gender-classification-dataset/Validation/female\"))\nprint(f\"There are {train_male} male and {train_female} female in the training set\")\nprint(f\"There are {valid_male} male and {valid_female} female in the validation set\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shapes = np.array([cv2.imread(path, -1).shape for path in np.random.choice(glob.glob(\"/kaggle/input/gender-classification-dataset/**/**/*\"), 1000, replace=False)])\nif not np.all(shapes==shapes[0]):\n    print(\"Not all images have the same shape\")\nelse:\n    print(f\"Almost all images are of shape {shapes[0]}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.min(shapes, axis=0), np.max(shapes, axis=0), np.mean(shapes, axis=0), np.median(shapes, axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"median_shape = np.median(shapes, axis=0).astype(int)\nmin_shape = np.min(shapes, axis=0).astype(int)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_imgs = np.random.choice(glob.glob(\"/kaggle/input/gender-classification-dataset/**/**/*\"), 30, replace=False)\nplt.figure(figsize = (18, 5))\nplt.suptitle(f\"Example of {len(random_imgs)} random images from all the data\")\nfor i in range(len(random_imgs)):\n    plt.subplot(3,10,i+1)\n    img = cv2.imread(random_imgs[i], -1)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    plt.imshow(img, cmap = 'gray')\n    plt.axis('off')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Loader","metadata":{}},{"cell_type":"markdown","source":"We will create a class to load and generate data to our model. The class will be responsible of reading, shuffling and feeding the data into the fully connected network. ","metadata":{}},{"cell_type":"code","source":"class DataLoader:\n    def __init__(self, data_path, batch_size, shape, flatten):\n        self._X, self._Y = self._read_data_path(data_path)\n        self._batch_size = batch_size\n        self.nb_iterations = self.__len__()//batch_size\n        self._shape = shape\n        self._flatten = flatten\n    \n    def __len__(self):\n        return len(self._X)\n    \n    def get_shape(self):\n        if self._flatten:\n            return np.prod(self._shape)\n        return self._shape + (3, )\n    \n    def _read_data_path(self, data_path):\n        X = glob.glob(os.path.join(data_path, \"male/*\"))\n        Y = [0]*len(X)\n        \n        X.extend(glob.glob(os.path.join(data_path, \"female/*\")))\n        Y.extend([1]*(len(X)-len(Y)))\n        \n        return np.array(X), np.array(Y)\n    \n\n    def _read_single_image(self, img_path, label):\n        img = tf.io.decode_png(\n                tf.io.read_file(img_path), channels=3, dtype=tf.uint8\n            )\n        img = tf.image.resize(img, self._shape) / 255.\n        if self._flatten:\n            img = tf.image.rgb_to_grayscale(img)\n            img = tf.reshape(img, (-1, ))\n        return img, label\n    \n    def get_dataset(self):\n        dataset = tf.data.Dataset.from_tensor_slices((self._X, self._Y))\n        dataset = dataset.shuffle(\n                buffer_size=self.__len__(), reshuffle_each_iteration=True\n            ).repeat()\n        dataset = dataset.map(self._read_single_image, tf.data.AUTOTUNE)\n        return dataset.batch(batch_size=self._batch_size, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Blocks","metadata":{}},{"cell_type":"code","source":"def conv_bn_relu(x, feature_maps, strides, kernel_size):\n    x = tf.keras.layers.Conv2D(\n          filters=feature_maps, kernel_size=kernel_size,\n          strides=strides, padding='same')(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.ReLU()(x)\n    return x\n\n\ndef residual_block(x, feature_maps_list, strides_list, kernel_size_list, drop_rate):\n    residual = x\n\n    if 2 in strides_list or x.shape[-1] < feature_maps_list[-1]:\n        residual = conv_bn_relu(x, feature_maps_list[-1], strides=max(strides_list), kernel_size=1)\n\n    if drop_rate > 0:\n        x = tf.keras.layers.SpatialDropout2D(drop_rate)(x)\n\n    for i in range(len(feature_maps_list)):\n        x = conv_bn_relu(x, feature_maps_list[i], strides=strides_list[i], kernel_size=kernel_size_list[i])\n\n    return tf.keras.layers.Add()([x, residual])\n\n\ndef dense_bn_relu(x, units, use_batch_norm, drop_rate):\n    if drop_rate > 0:\n        x = tf.keras.layers.Dropout(drop_rate)(x)\n    x = tf.keras.layers.Dense(units=units)(x)\n    if use_batch_norm:\n        x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.ReLU()(x)\n    return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Network","metadata":{}},{"cell_type":"code","source":"def create_dense_model(input_size, hidden_units, use_batch_norm, drop_rate):\n    input_layer = tf.keras.Input((input_size, ))\n    x = input_layer\n    for i, units in enumerate(hidden_units):\n        rate = 0 if i == 0 else drop_rate\n        x = dense_bn_relu(x, units, use_batch_norm=use_batch_norm, drop_rate=rate)\n    \n    return tf.keras.Model(input_layer, x)\n\ndef create_conv_model(input_size, config):\n    input_layer = tf.keras.Input(input_size)\n    x = input_layer\n    for i in range(len(config[\"kernel_size\"])):\n        x = residual_block(x, config[\"feature_maps\"][i], config[\"strides\"][i],\n                           config[\"kernel_size\"][i], config[\"drop_rate\"][i])\n    \n    x = tf.reduce_mean(x, axis=(1, 2))\n    \n    for units in config[\"dense\"][:-1]:\n        x = dense_bn_relu(x, units, use_batch_norm=True, drop_rate=0)\n    \n    x = tf.keras.layers.Dense(config[\"dense\"][-1])(x)\n        \n    return tf.keras.Model(input_layer, x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Optimizer","metadata":{}},{"cell_type":"code","source":"def create_optimizer(lr, nb_iterations, use_cosine_decay=False):\n    if use_cosine_decay:\n        alpha = 0.01\n        cycle = 10\n        decay_steps = cycle * nb_iterations\n        lr = tf.keras.optimizers.schedules.CosineDecayRestarts(\n                    lr,\n                    decay_steps,\n                    t_mul=1.0,\n                    m_mul=1.0,\n                    alpha=alpha,\n                )\n    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n    return optimizer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size=32\nresize_shape=(100, 100)\ntraining_path=\"/kaggle/input/gender-classification-dataset/Training\"\nvalidation_path=\"/kaggle/input/gender-classification-dataset/Validation\"\n\ntraining_data = DataLoader(training_path, batch_size, resize_shape, flatten=False)\nvalidation_data = DataLoader(validation_path, batch_size, resize_shape, flatten=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = {\n    \"kernel_size\": [[3], [3, 3], [3, 3], [3, 3]],\n    \"feature_maps\": [[8], [16, 16], [32, 32], [64, 64]],\n    \"strides\": [[1], [2, 1], [2, 1], [2, 1]],\n    \"drop_rate\": [0, 0.2, 0.2, 0.2],\n    \"dense\": [50, 1]\n}\nmodel = create_conv_model(training_data.get_shape(), config)\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learning_rate=0.01\noptimizer = create_optimizer(learning_rate, training_data.nb_iterations, True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs=50\nloss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\nmodel.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n\nhistory = model.fit(training_data.get_dataset(),\n                    validation_data=validation_data.get_dataset(),\n                    epochs=epochs, steps_per_epoch=training_data.nb_iterations, validation_steps=validation_data.nb_iterations)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loss = history.history['loss']\ntrain_acc = history.history['accuracy']\nvalid_loss = history.history['val_loss']\nvalid_acc = history.history['val_accuracy']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(12, 6))\nplt.suptitle(\"Learning Curves\")\n    \nplt.subplot(121)\nplt.title(\"cross entropy\")\nplt.plot(np.arange(1, len(train_loss)+1), train_loss, label='training', c='b')\nplt.plot(np.arange(1, len(valid_loss)+1), valid_loss, label='validation', c='r')\nplt.xlim(1, epochs + epochs//10)\nplt.xticks(np.arange(0, epochs + epochs//10, epochs//10))\nhandles, labels = plt.gca().get_legend_handles_labels()\nby_label = dict(zip(labels, handles))\nplt.legend(by_label.values(), by_label.keys(), loc='upper right')\n\nplt.subplot(122)\nplt.title(\"accuracy\")\nplt.plot(np.arange(1, len(train_acc)+1), train_acc, label='training', c='b')\nplt.plot(np.arange(1, len(valid_acc)+1), valid_acc, label='validation', c='r')\nplt.xlim(1, epochs + epochs//10)\nplt.xticks(np.arange(0, epochs + epochs//10, epochs//10))\nhandles, labels = plt.gca().get_legend_handles_labels()\nby_label = dict(zip(labels, handles))\nplt.legend(by_label.values(), by_label.keys(), loc='lower right')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test the model on new images","metadata":{}},{"cell_type":"code","source":"fake_faces = []\nfor img_path in glob.glob(\"/kaggle/input/fake-faces/*\"):\n    img = cv2.cvtColor(cv2.imread(img_path, -1), cv2.COLOR_BGR2RGB)\n    fake_faces.append(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 5))\nfor i in range(len(fake_faces)):\n    plt.subplot(1, len(fake_faces), i+1)\n    plt.imshow(fake_faces[i])\n    plt.axis('off')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_faces = []\nfor img in fake_faces:\n    img = cv2.resize(img, resize_shape)\n    img = img/255\n    batch_faces.append(img)\n    \nbatch_faces = np.array(batch_faces)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = model(batch_faces)\npreds = tf.math.sigmoid(preds)\ngenders =  ['male' if pred < 0.5 else \"female\" for pred in preds]\nplt.figure(figsize=(18, 5))\nfor i in range(len(fake_faces)):\n    plt.subplot(1, len(fake_faces), i+1)\n    plt.title(f\"gender: {genders[i]}\\np(y=1/X,A)={np.round(preds[i][0], 2):.2f}\", fontsize=10)\n    plt.imshow(fake_faces[i])\n    plt.axis('off')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}