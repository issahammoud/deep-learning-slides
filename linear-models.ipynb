{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "lhjXbxhKA7F1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iASdWlNjkmkY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "sns.set()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression"
      ],
      "metadata": {
        "id": "cqO_DLgYlb49"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate linear data with random noise"
      ],
      "metadata": {
        "id": "75DlnLLpBCKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.arange(-10, 10.5, 0.5)\n",
        "\n",
        "Y = 2*X - 3\n",
        "Y = Y + np.random.normal(0, 1, Y.shape[0])"
      ],
      "metadata": {
        "id": "g0PfHO_Rlktk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, Y.shape"
      ],
      "metadata": {
        "id": "R_Tz4LYTBdAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.title(\"A set of points (x, y)\")\n",
        "plt.scatter(X, Y, c='r')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('Y')\n",
        "plt.axvline(x=0)\n",
        "plt.axhline(y=0)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "a7PyAvunlqg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Line of best fit\n",
        "1.   Find the line of best fit using the formula of a and b.\n",
        "2.   Check if you will get the same results with sklearn.\n",
        "3.   Plot the line alongside the points.\n",
        "\n"
      ],
      "metadata": {
        "id": "jltfCpnepDxj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_line_of_best_fit(X, Y):\n",
        "  \"\"\"\n",
        "  X: 1D np.array of type float representing the input\n",
        "  Y: 1D np.array of type float representing the label\n",
        "  return: (a, b) the line parameter\n",
        "  \"\"\"\n",
        "  a = ((X - X.mean())*(Y - Y.mean())).sum()/((X - X.mean())**2).sum()\n",
        "  b = Y.mean() - a*X.mean()\n",
        "  return a, b\n",
        "\n",
        "a_1, b_1 = compute_line_of_best_fit(X, Y)\n",
        "a_1, b_1"
      ],
      "metadata": {
        "id": "NF-jTELwmCmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def compute_line_of_best_fit_with_sklearn(X, Y):\n",
        "  \"\"\"\n",
        "  X: 1D np.array of type float representing the input\n",
        "  Y: 1D np.array of type float representing the label\n",
        "  return: (a, b) the line parameter\n",
        "  \"\"\"\n",
        "  reg = LinearRegression().fit(X.reshape(-1, 1), Y.reshape(-1, 1))\n",
        "  return reg.coef_[0], reg.intercept_[0]\n",
        "\n",
        "a_2, b_2 = compute_line_of_best_fit_with_sklearn(X, Y)\n",
        "a_2, b_2"
      ],
      "metadata": {
        "id": "AXRXJRWBp2iy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "line_1 = a_1*X + b_1\n",
        "line_2 = a_2*X + b_2\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.title(\"A set of points (x, y)\")\n",
        "plt.scatter(X, Y, c='r')\n",
        "plt.plot(X, line_1, c='b')\n",
        "plt.plot(X, line_2, c='g')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('Y')\n",
        "plt.axvline(x=0)\n",
        "plt.axhline(y=0)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lTgsEP4kpcpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate linear data in high dimensional space"
      ],
      "metadata": {
        "id": "a94f-gD6CPEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p, q, n = 70, 50, 100\n",
        "X = np.random.normal(0, 10, (p, n))\n",
        "Y = np.random.normal(2, 5, (q, p))@X + np.random.normal(0, 10, (q, 1))"
      ],
      "metadata": {
        "id": "cANGO_99qd7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, Y.shape"
      ],
      "metadata": {
        "id": "Mt5fuUpLCfPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_normal_equation(X, Y):\n",
        "  \"\"\"\n",
        "  X: 2D np.array of shape (number_of_features, number_of_samples) representing the input\n",
        "  Y: 2D np.array of shape (number_of_features, number_of_samples) representing the label\n",
        "  \"\"\"\n",
        "  # stack the vectors of ones on top of X\n",
        "  new_X = np.vstack([np.ones(X.shape[1]), X])\n",
        "  term_1 = np.dot(Y, new_X.T)\n",
        "  # np.linalg.inv compute the inverse of a matrix\n",
        "  term_2 = np.linalg.inv(np.dot(new_X, new_X.T))\n",
        "  A = np.dot(term_1, term_2)\n",
        "  return A[:, 1:], A[:, 0]\n",
        "\n",
        "\n",
        "A_1, b_1 = compute_normal_equation(X, Y)"
      ],
      "metadata": {
        "id": "k_K7aXZ6tFeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_normal_equation_with_sklearn(X, Y):\n",
        "  \"\"\"\n",
        "  X: 2D np.array of shape (number_of_features, number_of_samples) representing the input\n",
        "  Y: 2D np.array of shape (number_of_features, number_of_samples) representing the label\n",
        "  \"\"\"\n",
        "  reg = LinearRegression().fit(X.T, Y.T)\n",
        "  return reg.coef_, reg.intercept_\n",
        "\n",
        "A_2, b_2 = compute_normal_equation_with_sklearn(X, Y)"
      ],
      "metadata": {
        "id": "DOkZogrQtIDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.testing.assert_allclose(A_1, A_2)"
      ],
      "metadata": {
        "id": "y8dVLpnXuOUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.testing.assert_allclose(b_1, b_2)"
      ],
      "metadata": {
        "id": "V3o-1wp6uXBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression"
      ],
      "metadata": {
        "id": "ABj707P-VHi1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate random data that are linearly separable"
      ],
      "metadata": {
        "id": "fVUwquQ0C7Uo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.arange(2, 23, 0.1)\n",
        "\n",
        "y = 2*x + 10\n",
        "y_1 = y + np.random.normal(0, 10, y.shape[0])\n",
        "\n",
        "y = 2*x - 40\n",
        "y_2 = y + np.random.normal(0, 10, y.shape[0])\n",
        "\n",
        "X_1 = np.stack([x, y_1])\n",
        "X_2 = np.stack([x, y_2])\n",
        "X = np.concatenate([X_1, X_2], axis=1)\n",
        "Y = np.array([0]*x.shape[0] + [1]*x.shape[0]).reshape(1, -1)"
      ],
      "metadata": {
        "id": "-DreX_jwudeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, Y.shape"
      ],
      "metadata": {
        "id": "8ib_lmhtDBtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "plt.title(\"A set of points in 2D\")\n",
        "plt.scatter(x, y_1, c='r')\n",
        "plt.scatter(x, y_2, c='r', marker='x')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.axvline(x=0)\n",
        "plt.axhline(y=0)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oW4kxBzKVOnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "  \"\"\"\n",
        "  x: np.array of any shape to apply sigmoid elementwise on it.\n",
        "  return: np.array\n",
        "  \"\"\"\n",
        "  return 1/(1+np.exp(-x))\n",
        "\n",
        "def logistic_regression(X, a, b):\n",
        "  \"\"\"\n",
        "  X: np.array representing the input to the logistic regression\n",
        "  a, b: parameters of the logisitc regression\n",
        "  return: a probability value following the formula of logistic regression\n",
        "  \"\"\"\n",
        "  return sigmoid(np.dot(a, X)+b)\n",
        "\n",
        "def gradient_a(X, Y, pred):\n",
        "  \"\"\"\n",
        "  Compute the average gradient w.r.t a\n",
        "  X: input data\n",
        "  Y: labels\n",
        "  pred: predictions\n",
        "  return: the gradient estimate w.r.t a\n",
        "  \"\"\"\n",
        "  return np.mean((-Y + pred)*X, axis=1, keepdims=True).T\n",
        "\n",
        "def gradient_b(Y, pred):\n",
        "  \"\"\"\n",
        "  Compute the average gradient w.r.t b\n",
        "  Y: labels\n",
        "  pred: predictions\n",
        "  return: the gradient estimate w.r.t b\n",
        "  \"\"\"\n",
        "  return np.mean(-Y + pred)"
      ],
      "metadata": {
        "id": "tiEtx31da8iv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(X, Y, initial_a, initial_b, step):\n",
        "  a, b = initial_a, initial_b\n",
        "\n",
        "  pred = logistic_regression(X, a, b)\n",
        "  grad_a = gradient_a(X, Y, pred)\n",
        "  grad_b = gradient_b(Y, pred)\n",
        "\n",
        "  count = 0\n",
        "  while(np.mean(grad_a**2) > 0.0001 or np.abs(grad_b) > 0.0001):\n",
        "    a = a - step*grad_a\n",
        "    b = b - step*grad_b\n",
        "\n",
        "    pred = logistic_regression(X, a, b)\n",
        "    grad_a = gradient_a(X, Y, pred)\n",
        "    grad_b = gradient_b(Y, pred)\n",
        "    count +=1\n",
        "    if count > 1e6:\n",
        "      print(\"algorithm diverged!\")\n",
        "      break\n",
        "  return a, b, count\n",
        "\n",
        "\n",
        "def momentum_gradient_descent(X, Y, initial_a, initial_b, step, alpha):\n",
        "  a, b = initial_a, initial_b\n",
        "\n",
        "  v_a = np.zeros_like(initial_a)\n",
        "  v_b = 0\n",
        "  pred = logistic_regression(X, a, b)\n",
        "  grad_a = gradient_a(X, Y, pred)\n",
        "  grad_b = gradient_b(Y, pred)\n",
        "  count = 0\n",
        "\n",
        "  while(np.mean(grad_a**2) > 0.0001 or np.abs(grad_b) > 0.0001):\n",
        "    v_a = alpha*v_a - step*grad_a\n",
        "    v_b = alpha*v_b - step*grad_b\n",
        "    a = a + v_a\n",
        "    b = b + v_b\n",
        "\n",
        "    pred = logistic_regression(X, a, b)\n",
        "    grad_a = gradient_a(X, Y, pred)\n",
        "    grad_b = gradient_b(Y, pred)\n",
        "    count +=1\n",
        "    if count > 1e6:\n",
        "      print(\"algorithm diverged!\")\n",
        "      break\n",
        "\n",
        "  return a, b, count\n",
        "\n",
        "\n",
        "step = 0.1\n",
        "alpha = 0.9999\n",
        "initial_a, initial_b = np.random.normal(scale=0.1, size=(1, 2)), 0\n",
        "# a_1, b_1, count_1 = gradient_descent(X, Y, initial_a, initial_b, step)\n",
        "a_2, b_2, count_2 = momentum_gradient_descent(X, Y, initial_a, initial_b, step, alpha)"
      ],
      "metadata": {
        "id": "vBSbaKeJVW6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_1, count_2"
      ],
      "metadata": {
        "id": "9tdRuGQry8Oh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def logistic_regression_with_sklearn(X, Y):\n",
        "  clf = LogisticRegression(penalty=None).fit(X.T, Y.T)\n",
        "  return clf.coef_, clf.intercept_\n",
        "\n",
        "a_3, b_3 = logistic_regression_with_sklearn(X, Y)"
      ],
      "metadata": {
        "id": "ofmGUer3fWfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "line_1 = -a_1[0][0]*x/a_1[0][1] -b_1/a_1[0][1]\n",
        "line_2 = -a_3[0][0]*x/a_3[0][1] -b_3/a_3[0][1]"
      ],
      "metadata": {
        "id": "h5w-uWERVcj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "plt.title(\"A set of points in 2D\")\n",
        "plt.scatter(x, y_1, c='r')\n",
        "plt.scatter(x, y_2, c='r', marker='x')\n",
        "plt.plot(x, line_1, c='y')\n",
        "plt.plot(x, line_2, c='g')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.axvline(x=0)\n",
        "plt.axhline(y=0)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ENmY2nG4e_M7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F33e0PHofN_4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}